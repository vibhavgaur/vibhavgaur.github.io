<!DOCTYPE html>
<html lang="en">

<head>
	<title>Visual Odometry (Part&nbsp;1)</title>
	<link rel="stylesheet" type="text/css" href="https://vibhavgaur.github.io/theme/css/base.css"/>
	<link rel="stylesheet" type="text/css" href="https://vibhavgaur.github.io/theme/css/code.css"/>
</head>

<body>
	<div id="topBox">
		<h1 class="siteTitle"><a href="https://vibhavgaur.github.io/index.html">Vibhav Gaur</a></h1>
		<div id="canvasDiv">
			<!-- This div is to make the canvas clickable -->
			<span id="canvasContainer" title="Click to learn more">
			</span>
		</div>
	</div>

	<ul class="NavBar">
			<li><a href="/pages/blog.html">Blog</a></li>
			<li><a href="/pages/coursework.html">Coursework</a></li>
			<li><a href="/pages/projects.html">Projects</a></li>
	</ul>

		<div class="content">
	<h2>Visual Odometry (Part&nbsp;1)</h2>
	<label>Posted on <strong>August 27, 2021</strong></label>
		
	<p><strong>This post is first in a series on Visual Odometry. Find part 2 <a href="../visodo-2.html">here</a>.</strong></p>
<p>Your car&#8217;s odometer works by counting the rotations of the wheels and multiplying by the circumference of the wheel/tyre.
However, computer vision makes it possible to get similar measurements by just <em>looking</em> at the motion of the car.
This is Visual Odometry (<span class="caps">VO</span>) &#8212; odometry using&nbsp;vision.</p>
<p>In this post I am going to try and perform monocular <span class="caps">VO</span> (<span class="caps">VO</span> with one camera) on a stock dashcam video that I downloaded off the internet.
If <span class="caps">VO</span> is any good as far as applications are concerned, it should work on any video.
My goal for this post is to learn how to use the OpenCV python library and computer vision concepts in the process.
The code and video for this can be found on <a href="https://github.com/vibhavgaur/VisualOdometry">my GitHub</a>.</p>
<p>A note before we go ahead &#8212; I am still learning this stuff so I may promise something at the start of the post and not deliver on it (in the same post) because I got stuck or had to do something else.
But the point of this is to learn by feeling our way through this stuff, there are plenty of concrete resources if you want to get it right in the first try.
I feel this way is more conducive to&nbsp;learning.</p>
<h3>Main&nbsp;Idea</h3>
<p>The central idea in <span class="caps">VO</span> is that one can detect features in each frame, match those features across a number of frames, and therefore estimate the motion of the camera.
In this post, I will attempt the first portion of this problem which is to estimate camera motion between two successive frames.
Once I have that running, I will extend that to the whole video in a subsequent post.
Let&#8217;s get into&nbsp;it.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="c1"># %matplotlib inline</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="s2">&quot;DrivingVideo.mp4&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of frames in video: &quot;</span><span class="p">,</span> <span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_COUNT</span><span class="p">))</span>
<span class="n">W</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">)),</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Width, Height: &quot;</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p><code>Number of frames in video:  813.0</code><br>
<code>Width, Height:  1280 720</code>  </p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="n">frame1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
<span class="n">frame2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>There will be a lot of comparing two frames side by side, so I&#8217;m going to write a handy function to take care of&nbsp;that.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="k">def</span> <span class="nf">showImages</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">frame2</span><span class="p">):</span>
    <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">frame1</span><span class="p">),</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">frame2</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">),</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">),</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Frame 1&#39;</span><span class="p">),</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;Frame 2&#39;</span><span class="p">)</span>

<span class="n">showImages</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">frame2</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p align="center">
<img src="../images/VisOdo1/output_5_0.png">
</p>

<h3>Feature&nbsp;detection</h3>
<p>I will be detecting <span class="caps">ORB</span> features in the images. 
I don&#8217;t have a good idea of what exactly these features look for, but I do know that they are free to use (unlike <span class="caps">SIFT</span> features) and perform quite well.
The key is to write code that is indifferent to the feature detector used.
OpenCV&#8217;s design lends itself well to this style, since all I have to change is the first line below if I wished to use a different&nbsp;detector.</p>
<p>A <strong>feature descriptor</strong> is a vector of numbers that tries to uniquely identify a feature.
One can think of it like a fingerprint for the feature.
When we find matches for features in different frames, we will do so using the&nbsp;descriptors.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="n">detector</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ORB_create</span><span class="p">()</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">kp2</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">detector</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">frame2</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of keypoints: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">kp1</span><span class="p">),</span><span class="s2">&quot; and &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">kp2</span><span class="p">))</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">kp1</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">frame2</span><span class="p">,</span> <span class="n">kp2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Descriptors: &quot;</span><span class="p">,</span> <span class="n">des1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">des2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">frame1_kp</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawKeypoints</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">flags</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">frame2_kp</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawKeypoints</span><span class="p">(</span><span class="n">frame2</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">flags</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">showImages</span><span class="p">(</span><span class="n">frame1_kp</span><span class="p">,</span> <span class="n">frame2_kp</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p><code>Number of keypoints:  500  and  500</code><br>
<code>Descriptors:  (500, 32) (500, 32)</code>  </p>
<p align="center">
<img src="../images/VisOdo1/output_7_1.png">
</p>

<p>Using the default settings for the <span class="caps">ORB</span> detector, 500 features are detected. 
These points are called the <strong>keypoints</strong> and they are drawn on their respective frames as green dots.
The detected features should ideally be distributed well all over the image for a good estimation of camera motion ultimately.
This is not the case here &#8212; we will have to do something about that.
Also note that the descriptors are a 500 $\times$ 32 matrix, i.e. for each keypoint, there is a 32-dimensional vector that is its descriptor.
I believe the 32 is a function of the definition of the&nbsp;detector.</p>
<h3>Feature&nbsp;matching</h3>
<p>There are many algorithms to match features, but I went with the simple (yet effective) brute-force matcher.
The metric being used to match features is the Hamming Norm.
I think its just matches features by looking at which descriptors end up closest in that 32-dimensional descriptor space, i.e. its just looking at the <a href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a> between those 32-dimensional&nbsp;vectors.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="n">matcher</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">BFMatcher</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">NORM_HAMMING</span><span class="p">,</span> <span class="n">crossCheck</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">matcher</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span> <span class="n">des2</span><span class="p">)</span>

<span class="n">matches</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">distance</span><span class="p">)</span>
<span class="n">framesMatched</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">frame2</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">]),</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Good matches&quot;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">framesMatched</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>
</td></tr></table>
<p align="center">
<img src="../images/VisOdo1/output_9_0.png">
</p>

<p>The image above (poorly) shows the top 10 matches between the two frames.
As can be seen, they correspond to the same objects in physical space (such as the corner of the window in the top right).
This is a good thing.
However, not all matches are good quality like that.
If I look at the 10 worst matches, this is what we&nbsp;get.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="n">framesBadMatches</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">frame1</span><span class="p">,</span> <span class="n">kp1</span><span class="p">,</span> <span class="n">frame2</span><span class="p">,</span> <span class="n">kp2</span><span class="p">,</span> <span class="n">matches</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:],</span> <span class="kc">None</span><span class="p">,</span> <span class="n">flags</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">]),</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Bad matches&quot;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">framesBadMatches</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>
</td></tr></table>
<p align="center">
<img src="../images/VisOdo1/output_11_0.png">
</p>

<p>Notice how these &#8220;matches&#8221; don&#8217;t actually point to the same physical object &#8212; making these bad matches.
We want to get rid of bad matches so it doesn&#8217;t throw off our eventual motion estimation.
Here is where some knowledge about camera models and projective geometry will come&nbsp;in.</p>
<p>Let&#8217;s check how good our matches really are. We can look at the distance of each match &#8212; the lower the&nbsp;better.</p>
<table class="codeBlocktable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codeBlock"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of matches: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">))</span>
<span class="nb">print</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">distance</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">])</span>
</code></pre></div>
</td></tr></table>
<p><code>Number of matches:  383</code><br>
<code>[2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 33.0, 33.0, 33.0, 33.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 37.0, 37.0, 38.0, 38.0, 38.0, 38.0, 39.0, 39.0, 39.0, 40.0, 40.0, 41.0, 41.0, 41.0, 42.0, 42.0, 42.0, 42.0, 43.0, 43.0, 44.0, 47.0, 48.0, 49.0, 50.0, 52.0, 52.0, 52.0, 53.0, 53.0, 55.0, 55.0, 56.0, 57.0, 57.0, 59.0, 60.0, 62.0, 62.0, 63.0, 65.0, 67.0, 69.0, 71.0, 74.0]</code>  </p>
<p>Hmm, that doesn&#8217;t look too promising.
We have 383 matches from our 500 keypoints, but a lot of them are kinda far in terms of the Hamming distance. 
This means that a lot of them are bad features.
We will have to use a different method to find our matches.
I&#8217;ll look into that in my <a href="../visodo-2.html">next post</a>.</p>
<h3>References</h3>
<ul>
<li><a href="https://www.youtube.com/channel/UCf0WB91t8Ky6AuYcQV0CcLw">First Principles of Computer Vision</a> YouTube&nbsp;channel</li>
<li><a href="https://github.com/geohot/twitchslam">twitchslam</a> by George&nbsp;Hotz</li>
<li><a href="https://www.youtube.com/playlist?list=PLrHDCRerOaI9HfgZDbiEncG5dx7S3Nz6X"><span class="caps">KITTI</span> Odometry with OpenCV Python</a> by Nate&nbsp;Cibik</li>
<li>Visual Odometry by David Scaramuzza and Friedrich&nbsp;Fraundorfer</li>
</ul>
		</div>

		<footer>
			<ul class="footer">
				<li><a href="https://github.com/vibhavgaur">GitHub</a></li>
				<li><a href="mailto:vibhavgaur@me.com">Email</a></li>
				<li><a href="https://twitter.com/VibhavGaur">Twitter</a></li>
				<li><a href="https://www.linkedin.com/in/vibhav-gaur-775815137/">LinkedIn</a></li>
			</ul>
		</footer>
</body>

</html>